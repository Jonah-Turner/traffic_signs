# -*- coding: utf-8 -*-
"""starter_signs.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1t3OyDcB_Zt82J_AvaSQhVFgUX8xHYMMB
"""

# Note: After you run this cell, the training and test data will be available in
# the file browser. (Click the folder icon on the left to view it)
#
# If you don't see the data after the cell completes, click the refresh button
# in the file browser (folder icon with circular arrow)

# First, let's download and unzip the data
# !echo "Downloading files..."
# !wget -q https://github.com/byui-cse/cse450-course/raw/master/data/roadsigns/training1.zip
# !wget -q https://github.com/byui-cse/cse450-course/raw/master/data/roadsigns/training2.zip
# !wget -q https://github.com/byui-cse/cse450-course/raw/master/data/roadsigns/test.zip
# !wget -q https://github.com/byui-cse/cse450-course/raw/master/data/roadsigns/test_classes.csv

# !echo "Unzipping files..."
# !unzip -q /content/training1.zip
# !unzip -q /content/training2.zip
# !unzip -q /content/test.zip

# # Combine the two traning directories
# !echo "Merging training data..."
# !mkdir /content/training
# !mv /content/training1/* /content/training
# !mv /content/training2/* /content/training

# # Cleanup
# !echo "Cleaning up..."
# !rmdir /content/training1
# !rmdir /content/training2
# !rm training1.zip
# !rm training2.zip
# !rm test.zip

# !echo "Data ready."

"""# Training Images

Note, due to github size constraints, the training data is split into two zip files, training1.zip and training2.zip

In the training directories, there is one subdirectory for each of the 43 classes (0000 - 00043).
Each subdirectory contains the corresponding training images for that class.

The images are jpeg images (RGB color). Files are numbered in two parts:

   XXXXX_YYYYY.ppm

The first part, XXXXX, represents the track number. All images of one class
with identical track numbers originate from one single physical traffic sign.

The second part, YYYYY, is a running number within the track. The temporal order
of the images is preserved.


# Test Images

The images are jpeg images (RGB color). Files are numbered in ascending order:

   00000.ppm to 12629.ppm

Images are in random order, ie. there is no track structure or class information
as in the training set.

The class labels for the test images are stored in a file called test_classes.csv
"""

# Import libraries
import pandas as pd
import tensorflow as tf
from tensorflow import keras
import tensorflow_datasets as tfds
import numpy as np

# Create an image training dataset
from keras.preprocessing import image_dataset_from_directory
# from tensorflow.keras.preprocessing import image_dataset_from_directory

# We're using keras' image_dataset_from_directory method to load our image data.
# See (https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory) for details
#
# A couple of things to note:
# 1. We're specifying a number for the seed, so we'll always get the same shuffle and split of our images.
# 2. Class names are inferred automatically from the image subdirectory names.
# 3. We're splitting the training data into 80% training, 20% validation.


training_dir = '/content/training/'
image_size = (100, 100)

# Split up the training data images into training and validations sets
training_data = image_dataset_from_directory(training_dir, validation_split=.2, subset='training', seed=42, image_size=image_size)
validation_data = image_dataset_from_directory(training_dir, validation_split=.2, subset='validation', seed=42, image_size=image_size)



# Understand the data
print("Training Set:", len(training_data))
print("Validation Set:", len(validation_data))

"""## Sample Data"""

import matplotlib.pyplot as plt

# View first 9 images and their class labels
plt.figure(figsize=(10, 10))
for images, labels in training_data.take(1):
  for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(images[i].numpy().astype("uint8"))
    plt.title(training_data.class_names[labels[i]])
    plt.axis("off")

for images, labels in training_data:
  print(images.shape)
  print(labels.shape)
  break

AUTOTUNE = tf.data.AUTOTUNE

training_data = training_data.cache().prefetch(buffer_size=AUTOTUNE)
validation_data = validation_data.cache().prefetch(buffer_size=AUTOTUNE)

"""# Model"""

# Build a model...

from keras import layers
# from tensorflow.keras import layers

num_classes = 43

model = tf.keras.Sequential([
  layers.experimental.preprocessing.Rescaling(1./255),
  layers.Conv2D(32, 3, activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(32, 3, activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(32, 3, activation='relu'),
  layers.MaxPooling2D(),
  layers.Flatten(),
  layers.Dense(128, activation='relu'),
  layers.Dense(num_classes)
])

model.compile(
  optimizer='adam',
  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),
  metrics=['accuracy']
  )

# !mkdir -p saved_model

"""## 3 epochs"""

## model is building off previous fits...

history = model.fit(
  training_data,
  validation_data=validation_data,
  epochs=3
)

model.save('saved_model/model_3')

hist1 = pd.DataFrame(history.history)
hist1['epoch'] = history.epoch

plt.title('3 epochs', loc='center', pad=None)
plt.plot(hist1['loss'], label='loss')
plt.plot(hist1['val_loss'], label='val_loss')
plt.xlabel('Epoch')
plt.ylabel('Error')
plt.legend()
plt.grid(True)

"""## 10 epochs"""

history = model.fit(
  training_data,
  validation_data=validation_data,
  epochs=7
)

model.save('saved_model/model_10')

hist2 = pd.DataFrame(history.history)
hist2['epoch'] = history.epoch

hist2 = pd.concat([hist1, hist2])
hist2 = hist2.reset_index(drop=True)

plt.plot(hist2['loss'], label='loss')
plt.plot(hist2['val_loss'], label='val_loss')
plt.xlabel('Epoch')
plt.ylabel('Error')
plt.legend()
plt.grid(True)

hist2

"""## 20 epochs"""

history = model.fit(
  training_data,
  validation_data=validation_data,
  epochs=10
)

model.save('saved_model/model_20')

hist3 = pd.DataFrame(history.history)
hist3['epoch'] = history.epoch

hist3 = pd.concat([hist2, hist3])
hist3 = hist3.reset_index(drop=True)

plt.plot(hist3['loss'], label='loss')
plt.plot(hist3['val_loss'], label='val_loss')
plt.xlabel('Epoch')
plt.ylabel('Error')
plt.legend()
plt.grid(True)



"""## 30 epochs"""

history = model.fit(
  training_data,
  validation_data=validation_data,
  epochs=10
)

model.save('saved_model/model_30')

hist4 = pd.DataFrame(history.history)
hist4['epoch'] = history.epoch

hist4 = pd.concat([hist3, hist4])
hist4 = hist4.reset_index(drop=True)

plt.plot(hist4['loss'], label='loss')
plt.plot(hist4['val_loss'], label='val_loss')
plt.xlabel('Epoch')
plt.ylabel('Error')
plt.legend()
plt.grid(True)

hist4

"""# Testing the model
Once you have built and trained your model, the next step is to run the test images through it and see how well your model does at making predictions for images it has never seen before.

Since loading these images and formatting them for the model can be tricky, you may find the following code useful. This code only uses your model to predict the class label for a given image. You'll still need to compare those predictions to the "ground truth" class labels in `test_classes.csv` to evaluate how well the model does.

    import pathlib
    
    def predict_an_image(model, file_path):
        # Load the image
        img = keras.preprocessing.image.load_img(file_path, target_size=(100, 100))
    
        # Get the image into the shape we need for our network
        img_array = keras.preprocessing.image.img_to_array(img)
        img_array = tf.expand_dims(img_array, 0)
    
        # Predict the class
        predictions = model.predict(img_array)
        score = tf.nn.softmax(predictions[0])
        return np.argmax(score)
    
    # Loop through all images in our test directory and make
    # a prediction
    testdir = pathlib.Path('/content/test')
    image_paths = list(testdir.glob('*.jpg'))
    for image_path in image_paths:
        prediction = predict_an_image(model, str(image_path))
        print(image_path, prediction)
  
"""

model_3 = tf.keras.models.load_model('saved_model/model_3')
model_10 = tf.keras.models.load_model('saved_model/model_10')
model_20 = tf.keras.models.load_model('saved_model/model_20')
model_30 = tf.keras.models.load_model('saved_model/model_30')

import pathlib

def predict_an_image(model, file_path):
    # Load the image
    img = keras.preprocessing.image.load_img(file_path, target_size=(100, 100))

    # Get the image into the shape we need for our network
    img_array = keras.preprocessing.image.img_to_array(img)
    img_array = tf.expand_dims(img_array, 0)

    # Predict the class
    predictions = model.predict(img_array)
    score = tf.nn.softmax(predictions[0])
    return np.argmax(score)

# Loop through all images in our test directory and make
# a prediction
testdir = pathlib.Path('/content/test')
image_paths = list(testdir.glob('*.jpg'))
df = pd.DataFrame()
df['dir'] = image_paths
df['dir'] = df['dir'].astype(str)
df['id'] = df['dir'].str.slice(14,24)
# df['pred'], df['test'] = 0, 0
df = df.sort_values(by='id')
df = df.reset_index(drop=True)
df

def getPred(model):
  test_dir = '/content/'
  image_size = (100, 100)
  test_datagen = tf.keras.preprocessing.image.ImageDataGenerator()
  test_generator = test_datagen.flow_from_directory(
          test_dir,
          classes=['test'], #this is the folder that holds the test images
          target_size=image_size,
          class_mode='sparse',
          shuffle=False)
  # print(test_generator.next())
  pred_test = model.predict(test_generator, use_multiprocessing=True)
  y_pred = [np.argmax(probas) for probas in pred_test]
  return y_pred

df['pred_3'] = getPred(model_3)
df['pred_10'] = getPred(model_10)
df['pred_20'] = getPred(model_20)
df['pred_30'] = getPred(model_30)
df

test = pd.read_csv('/content/test_classes.csv')
df['actual'] = test['ClassId']
# df['diff'] = abs(df['pred'] - df['actual'])
df['correct_3'] = (df['pred_3'] == df['actual']).astype(int)
df['correct_10'] = (df['pred_10'] == df['actual']).astype(int)
df['correct_20'] = (df['pred_20'] == df['actual']).astype(int)
df['correct_30'] = (df['pred_30'] == df['actual']).astype(int)
df

print (df.correct_3.mean())
print (df.correct_10.mean())
print (df.correct_20.mean())
print (df.correct_30.mean())

df.correct_30.value_counts()

from sklearn.metrics import f1_score
metric = pd.DataFrame()
metric['class'] = range(0,43)
metric['f1_3'] = f1_score(df['actual'], df['pred_3'], average=None)
metric['f1_10'] = f1_score(df['actual'], df['pred_10'], average=None)
metric['f1_20'] = f1_score(df['actual'], df['pred_20'], average=None)
metric['f1_30'] = f1_score(df['actual'], df['pred_30'], average=None)
import plotly.express as px
fig = px.bar(metric, x='class', y='f1_30')
fig.show()

metric.f1_30.mean()

import plotly.graph_objects as go

colors = ['lightslategray',] * 43

colors[6] = 'crimson'
colors[21] = 'crimson'
colors[30] = 'crimson'
colors[41] = 'crimson'

colors[13] = "dodgerblue"
colors[14] = "dodgerblue"
colors[17] = "dodgerblue"
colors[29] = "dodgerblue"

fig = go.Figure(data=[go.Bar(
    x=metric['class'],
    y=metric['f1_30'],
    marker_color=colors # marker color can be a single color value or an iterable
)])
fig.update_layout(title_text='Class Importance')

import plotly.graph_objects as go

classes = metric['class']

fig = go.Figure(data=[
    go.Bar(name='3 epochs', x=classes, y=metric['f1_3']),
    go.Bar(name='10 epochs', x=classes, y=metric['f1_10']),
    go.Bar(name='20 epochs', x=classes, y=metric['f1_20']),
    go.Bar(name='30 epochs', x=classes, y=metric['f1_30'])
])
# Change the bar mode
fig.update_layout(barmode='group')
fig.show()

from sklearn.metrics import classification_report

cr = classification_report(df['actual'], df['pred_30'], output_dict=True)

print('Classification Report:\n\n', classification_report(df['actual'], df['pred_30']))

df_cr = pd.DataFrame(cr).transpose()
df_cr

df_stat = df_cr.iloc[43:]
df_cr = df_cr.iloc[:43]

df_cr.precision.mean()

df_cr.recall.mean()

df_cr['f1-score'].mean()

df_stat.round(2)

# from google.colab import drive
drive.mount('/content/drive')

final_model = tf.keras.models.load_model('/content/saved_model/model_30')

# !pip install coremltools

# import coremltools as ct

# mlmodel = ct.convert(final_model)

# mlmodel.save('/content/drive/MyDrive/mlmodel')